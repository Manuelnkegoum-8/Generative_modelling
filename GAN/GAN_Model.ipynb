{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2e62ac5-d523-4f57-9cc9-f886a20f0728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils.metrics import AndersonDarlingDistance, KendallDependenceMetric\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acc93d44-e431-487f-bc67-7df02690689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load Dataset\n",
    "'''\n",
    "data = pd.read_csv('../data_train_log_return.csv', header=None).drop(columns=[0])\n",
    "scaler = MinMaxScaler().fit(data.values)\n",
    "X_train = torch.Tensor(scaler.transform(data.values)).to(device)\n",
    "# X_train = torch.Tensor(data.values).to(device)\n",
    "\n",
    "'''\n",
    "Load Metrics\n",
    "'''\n",
    "ad = AndersonDarlingDistance()\n",
    "kd = KendallDependenceMetric()\n",
    "\n",
    "def compute_metrics(batch):\n",
    "    size = batch.size(0)\n",
    "    device_ = batch.device\n",
    "    _,x = model.sample(size,device_)\n",
    "    anderson = ad(batch.clone().detach(), x.clone().detach())\n",
    "    kendall  = kd(batch.clone().detach(), x.clone().detach())\n",
    "    return anderson, kendall\n",
    "\n",
    "def visual_3D(data):\n",
    "    x = data[:,0]\n",
    "    y = data[:,1]\n",
    "    z = data[:,2]\n",
    "    color = data[:,3]  # 4th dimension\n",
    "    \n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    scatter = ax.scatter(x, y, z, c=color, cmap='viridis')\n",
    "    \n",
    "    plt.colorbar(scatter)\n",
    "    ax.set_xlabel('1st Dimension')\n",
    "    ax.set_ylabel('2nd Dimension')\n",
    "    ax.set_zlabel('3rd Dimension')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5956d3-7524-406b-a7c7-5446a6f8d518",
   "metadata": {},
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a8025fe-7941-4080-80e9-98769e8befc8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Data/.sys/envs/env0/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      " 16%|████▌                       | 492/3000 [00:04<00:22, 110.77it/s]/Data/.sys/envs/env0/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3549.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      " 17%|████▉                        | 515/3000 [00:04<00:24, 99.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/3000, Discriminator Loss: 0.3261, Generator Loss: 3.6719 \n",
      "              Anderson Darling Distance: 346.7607 \n",
      "              Kendall Dependence: 2.0394 \n",
      "              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████▏                 | 1021/3000 [00:09<00:18, 109.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/3000, Discriminator Loss: 0.7826, Generator Loss: 2.0984 \n",
      "              Anderson Darling Distance: 86.8297 \n",
      "              Kendall Dependence: 1.9564 \n",
      "              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████████████▋             | 1516/3000 [00:14<00:13, 108.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1500/3000, Discriminator Loss: 1.0084, Generator Loss: 1.2233 \n",
      "              Anderson Darling Distance: 7.2389 \n",
      "              Kendall Dependence: 2.0434 \n",
      "              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████████████████         | 2011/3000 [00:18<00:09, 108.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2000/3000, Discriminator Loss: 1.1034, Generator Loss: 1.1894 \n",
      "              Anderson Darling Distance: 2.6096 \n",
      "              Kendall Dependence: 1.9915 \n",
      "              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|██████████████████████▋    | 2517/3000 [00:23<00:04, 103.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2500/3000, Discriminator Loss: 1.1594, Generator Loss: 0.8848 \n",
      "              Anderson Darling Distance: 3.7332 \n",
      "              Kendall Dependence: 2.0555 \n",
      "              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 3000/3000 [00:27<00:00, 109.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3000/3000, Discriminator Loss: 1.2239, Generator Loss: 0.9146 \n",
      "              Anderson Darling Distance: 4.8529 \n",
      "              Kendall Dependence: 1.9500 \n",
      "              \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Model\n",
    "'''\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        w = 8\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, w),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(w, w),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(w, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Parameters\n",
    "latent_dim = 64  # latent dim\n",
    "data_dim = 4    # data dimension\n",
    "lr = 0.0001     # learn rate\n",
    "\n",
    "# initialize\n",
    "generator = Generator(latent_dim, data_dim).to(device)\n",
    "discriminator = Discriminator(data_dim).to(device)\n",
    "\n",
    "# BCE Loss and optimizer\n",
    "loss_function = nn.BCELoss()\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=lr)\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=lr)\n",
    "\n",
    "'''\n",
    "Training\n",
    "'''\n",
    "epochs = 3000\n",
    "batch_size = 512\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        real_data = torch.Tensor(X_train[i:min(i+batch_size, len(X_train))])\n",
    "        fake_data = generator(torch.randn(len(real_data), latent_dim).to(device))\n",
    "\n",
    "        # Train Discriminator\n",
    "        d_optimizer.zero_grad()\n",
    "        real_loss = loss_function(discriminator(real_data), torch.ones(len(real_data), 1).to(device))\n",
    "        fake_loss = loss_function(discriminator(fake_data.detach()), torch.zeros(len(real_data), 1).to(device))\n",
    "        d_loss = real_loss + fake_loss\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # Train Generator\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss = loss_function(discriminator(fake_data), torch.ones(len(real_data), 1).to(device))\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "    # Progress\n",
    "    if (epoch+1) % 500 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Discriminator Loss: {d_loss.item():.4f}, Generator Loss: {g_loss.item():.4f} \\n\\\n",
    "              Anderson Darling Distance: {float(ad.forward(real_data, fake_data)):.4f} \\n\\\n",
    "              Kendall Dependence: {float(kd.forward(real_data, fake_data)):.4f} \\n\\\n",
    "              \")\n",
    "\n",
    "torch.save(generator.state_dict(), 'GAN_Generator.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f640766a-e32f-4223-80db-c1fc4e50088d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anderson Darling Distance: 11.7325         \n",
      "Kendall Dependence: 2.0058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 100/100 [00:00<00:00, 145.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Anderson Darling Distance: 7.5966         \n",
      " Mean Kendall Dependence: 2.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Evaluation\n",
    "'''\n",
    "# Sampling\n",
    "sample = generator(torch.randn(len(X_train), latent_dim).to(device))\n",
    "\n",
    "print(f'Anderson Darling Distance: {float(ad.forward(X_train, sample)):.4f} \\\n",
    "        \\nKendall Dependence: {float(kd.forward(X_train, sample)):.4f}')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "ads = []\n",
    "kds = []\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    with torch.no_grad():\n",
    "        sample = generator(torch.randn(len(X_train), latent_dim).to(device))\n",
    "    ads.append(float(ad.forward(X_train, sample)))\n",
    "    kds.append(float(kd.forward(X_train, sample)))\n",
    "\n",
    "print(f'Mean Anderson Darling Distance: {np.mean(ads):.4f} \\\n",
    "        \\n Mean Kendall Dependence: {np.mean(kds):.4f}')\n",
    "\n",
    "# visual_3D(X_train.cpu().detach().numpy())\n",
    "# visual_3D(sample.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb31762b-b559-434f-959f-42ab523fcece",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Inference\n",
    "'''\n",
    "! /Data/.sys/envs/env0/bin/python GAN_inference.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
